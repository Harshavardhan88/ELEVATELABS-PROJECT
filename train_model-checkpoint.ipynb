{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ceb7fe-38b2-4f3a-b6ce-6fb6384621cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (0.10.21)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: absl-py in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (2.2.2)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (25.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (0.6.0)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (0.6.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (3.10.3)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (4.25.7)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from jax->mediapipe) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from jax->mediapipe) (1.15.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from matplotlib->mediapipe) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from matplotlib->mediapipe) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from matplotlib->mediapipe) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from matplotlib->mediapipe) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python mediapipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6624307b-25e3-4a0c-a92e-c5b11dd6eb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (0.10.21)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: absl-py in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (2.2.2)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (25.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (0.6.0)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (0.6.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (3.10.3)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (4.25.7)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (0.5.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (80.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from matplotlib->mediapipe) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from matplotlib->mediapipe) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from matplotlib->mediapipe) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python mediapipe tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b8fd2b0-f610-4ae2-82bc-9c91b2e7176d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0909 - loss: 3.3259 - val_accuracy: 0.0000e+00 - val_loss: 3.8938\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.0455 - loss: 3.1809 - val_accuracy: 0.0000e+00 - val_loss: 4.4029\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.1818 - loss: 3.0166 - val_accuracy: 0.0000e+00 - val_loss: 4.9151\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.2273 - loss: 2.8437 - val_accuracy: 0.0000e+00 - val_loss: 5.4361\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.3636 - loss: 2.5934 - val_accuracy: 0.0000e+00 - val_loss: 5.9492\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.6818 - loss: 2.3043 - val_accuracy: 0.0000e+00 - val_loss: 6.4297\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.7273 - loss: 1.9817 - val_accuracy: 0.0000e+00 - val_loss: 7.0539\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.8636 - loss: 1.6583 - val_accuracy: 0.0000e+00 - val_loss: 8.0813\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.8636 - loss: 1.3188 - val_accuracy: 0.0000e+00 - val_loss: 9.4334\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9091 - loss: 0.9772 - val_accuracy: 0.0000e+00 - val_loss: 10.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "data_dir = \"dataset/\"\n",
    "categories = sorted(os.listdir(data_dir))\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for label, category in enumerate(categories):\n",
    "    folder_path = os.path.join(data_dir, category)\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (64, 64))\n",
    "            data.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "\n",
    "X = np.array(data) / 255.0\n",
    "y = to_categorical(labels, num_classes=len(categories))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(categories), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "model.save(\"model/asl_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f279408-fa00-46a1-a5dd-6309aeb72b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HARSHAVARDHAN\\Desktop\\sign lang\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913aab4b-d729-4202-9490-9a85fe4fcca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\harshavardhan\\desktop\\sign lang\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcc1ad88-5241-4d10-969d-8f5485bcd547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 812.15it/s]\n",
      "B: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:02<00:00, 725.95it/s]\n",
      "C: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:02<00:00, 740.99it/s]\n",
      "D: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 899.72it/s]\n",
      "E: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 908.86it/s]\n",
      "F: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 787.99it/s]\n",
      "G: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 846.24it/s]\n",
      "H: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 841.64it/s]\n",
      "I: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:02<00:00, 748.18it/s]\n",
      "J: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 837.13it/s]\n",
      "K: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 815.52it/s]\n",
      "L: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 838.40it/s]\n",
      "M: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 817.87it/s]\n",
      "N: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 787.66it/s]\n",
      "O: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:02<00:00, 722.16it/s]\n",
      "P: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 757.27it/s]\n",
      "Q: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 755.69it/s]\n",
      "R: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:02<00:00, 736.15it/s]\n",
      "S: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:02<00:00, 695.65it/s]\n",
      "T: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 787.23it/s]\n",
      "U: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 763.28it/s]\n",
      "V: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 765.11it/s]\n",
      "W: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 763.56it/s]\n",
      "X: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:01<00:00, 781.72it/s]\n",
      "Y: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:02<00:00, 743.36it/s]\n",
      "Z: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:02<00:00, 697.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HARSHAVARDHAN\\Desktop\\sign lang\\venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 121ms/step - accuracy: 0.3658 - loss: 2.1565 - val_accuracy: 0.8606 - val_loss: 0.4674\n",
      "Epoch 2/5\n",
      "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 100ms/step - accuracy: 0.6754 - loss: 0.9868 - val_accuracy: 0.8969 - val_loss: 0.3347\n",
      "Epoch 3/5\n",
      "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 99ms/step - accuracy: 0.7190 - loss: 0.8432 - val_accuracy: 0.9124 - val_loss: 0.2645\n",
      "Epoch 4/5\n",
      "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 101ms/step - accuracy: 0.7483 - loss: 0.7554 - val_accuracy: 0.9167 - val_loss: 0.2482\n",
      "Epoch 5/5\n",
      "\u001b[1m975/975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 101ms/step - accuracy: 0.7614 - loss: 0.7197 - val_accuracy: 0.9171 - val_loss: 0.2461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained and saved.\n"
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "DATA_DIR = \"dataset/\"\n",
    "CLASSES = [chr(i) for i in range(ord('A'), ord('Z') + 1)]\n",
    "IMG_SIZE = 96\n",
    "X, y = [], []\n",
    "\n",
    "for idx, label in enumerate(CLASSES):\n",
    "    path = os.path.join(DATA_DIR, label)\n",
    "    for img in tqdm(os.listdir(path)[:1500], desc=label):  # Limit per class\n",
    "        try:\n",
    "            img_array = cv2.imread(os.path.join(path, img))\n",
    "            img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "            X.append(img_array)\n",
    "            y.append(idx)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "X = np.array(X) / 255.0\n",
    "y = to_categorical(y, num_classes=len(CLASSES))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(X_train)\n",
    "\n",
    "base_model = MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(CLASSES), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(datagen.flow(X_train, y_train, batch_size=32), validation_data=(X_test, y_test), epochs=5)\n",
    "\n",
    "model.save('model/asl_model.h5')\n",
    "print(\"✅ Model trained and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536df24b-9dc0-4b05-a839-28eaf1c9c999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signlang-env",
   "language": "python",
   "name": "signlang-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
